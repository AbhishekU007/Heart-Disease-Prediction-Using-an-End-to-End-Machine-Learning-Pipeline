{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe662ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6314c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create outputs directory\n",
    "os.makedirs(\"outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df760bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load dataset (UCI Heart Disease â€” processed Cleveland dataset)\n",
    "# Option A: If you have the CSV locally, change the path. Option B: Use this common cleaned CSV URL.\n",
    "# If running offline, download \"heart.csv\" (the common cleaned UCI version) to working dir.\n",
    "# Many cleaned copies are called \"heart.csv\" with columns: age,sex,cp,trestbps,chol,fbs,restecg,thalach,exang,oldpeak,slope,ca,thal,target\n",
    "\n",
    "csv_path = \"heart.csv\"  # replace if necessary\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"File heart.csv not found in working directory.\")\n",
    "    print(\"Please download the UCI/cleaned heart dataset and place as 'heart.csv'.\")\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Loaded dataset:\", csv_path)\n",
    "\n",
    "# If the file is present, proceed\n",
    "try:\n",
    "    df\n",
    "except NameError:\n",
    "    raise SystemExit(\"Load the dataset and restart.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ca1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Quick overview\n",
    "print(\"\\n--- Data Info ---\\n\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Head ---\\n\")\n",
    "display(df.head())\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nMissing values per column:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1030832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Basic stats (numeric)\n",
    "desc = df.describe().T\n",
    "desc['skew'] = df.skew()\n",
    "desc['kurtosis'] = df.kurtosis()\n",
    "desc['median'] = df.median()\n",
    "display(desc)\n",
    "\n",
    "# Save summary to CSV for report\n",
    "desc.to_csv(\"outputs/descriptive_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff071c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Target distribution\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Target Distribution (0 = No disease, 1 = Disease)')\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/target_distribution.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6313a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Numeric distributions (histograms)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols.remove('target')\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(6,3.5))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution: {col}')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"outputs/dist_{col}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc390c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Boxplots for outlier detection (select important numeric features)\n",
    "for col in ['chol','trestbps','oldpeak','thalach']:\n",
    "    if col in df.columns:\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.boxplot(x=df[col])\n",
    "        plt.title(f'Boxplot: {col}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"outputs/box_{col}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd384c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Correlation heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"outputs/correlation_matrix.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2696ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Scatter plots: age vs thalach and chol vs age\n",
    "if 'age' in df.columns and 'thalach' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(x='age', y='thalach', hue='target', data=df, alpha=0.8)\n",
    "    plt.title('Age vs Max Heart Rate (thalach)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/age_v_thalach.png\")\n",
    "    plt.close()\n",
    "\n",
    "if 'age' in df.columns and 'chol' in df.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(x='age', y='chol', hue='target', data=df, alpha=0.8)\n",
    "    plt.title('Age vs Serum Cholesterol (chol)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/age_v_chol.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa064a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Preprocessing: define feature sets\n",
    "# Define numerical and categorical columns based on typical UCI heart dataset\n",
    "num_features = ['age','trestbps','chol','thalach','oldpeak']\n",
    "cat_features = [c for c in df.columns if c not in num_features + ['target']]\n",
    "\n",
    "print(\"Numeric features:\", num_features)\n",
    "print(\"Categorical features:\", cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Build preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18d896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Train-test split\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Model pipelines\n",
    "lr_pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='liblinear'))\n",
    "])\n",
    "\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preproc', preprocessor),\n",
    "    ('clf', DecisionTreeClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Train models\n",
    "print(\"\\nTraining Logistic Regression...\")\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "print(\"Training Decision Tree...\")\n",
    "dt_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67506f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16. Predict and evaluate helper\n",
    "def evaluate_model(pipeline, X_test, y_test, model_name=\"Model\"):\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
    "    print(\"Accuracy:\", round(acc,4))\n",
    "    print(\"Precision:\", round(prec,4))\n",
    "    print(\"Recall:\", round(rec,4))\n",
    "    print(\"F1-score:\", round(f1,4))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "    # Save confusion matrix plot\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix: {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"outputs/cm_{model_name.replace(' ','_')}.png\")\n",
    "    plt.close()\n",
    "    return {'accuracy':acc,'precision':prec,'recall':rec,'f1':f1, 'confusion':cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56034ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. Evaluate both models\n",
    "lr_metrics = evaluate_model(lr_pipeline, X_test, y_test, \"Logistic Regression\")\n",
    "dt_metrics = evaluate_model(dt_pipeline, X_test, y_test, \"Decision Tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6261db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. Optional: Cross-validation for logistic regression\n",
    "cv_scores = cross_val_score(lr_pipeline, X, y, cv=5, scoring='accuracy')\n",
    "print(\"\\nLogistic Regression CV accuracy (5-fold):\", cv_scores, \"Mean:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dde8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19. Optional: Hyperparameter tuning for Decision Tree (GridSearch)\n",
    "param_grid = {\n",
    "    'clf__max_depth': [2,3,4,5,6,7,None],\n",
    "    'clf__min_samples_split': [2,4,6,8]\n",
    "}\n",
    "grid = GridSearchCV(dt_pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"\\nBest Decision Tree params:\", grid.best_params_)\n",
    "best_dt = grid.best_estimator_\n",
    "best_dt_metrics = evaluate_model(best_dt, X_test, y_test, \"Decision Tree (Tuned)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57201d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. Visualize Decision Tree (simple)\n",
    "# Plot tree from best_dt (needs feature names after preprocessing)\n",
    "# We'll get feature names from preprocessor\n",
    "onehot_cols = []\n",
    "if hasattr(preprocessor.named_transformers_['cat'].named_steps['onehot'], 'get_feature_names_out'):\n",
    "    cat_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(cat_features)\n",
    "else:\n",
    "    cat_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names(cat_features)\n",
    "feature_names = num_features + list(cat_names)\n",
    "try:\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plot_tree(best_dt.named_steps['clf'], feature_names=feature_names, filled=True, max_depth=3, fontsize=8)\n",
    "    plt.title(\"Decision Tree (truncated depth=3)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/decision_tree.png\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(\"Decision tree plotting failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19691c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Feature importance (from decision tree)\n",
    "try:\n",
    "    importances = best_dt.named_steps['clf'].feature_importances_\n",
    "    fi = pd.Series(importances, index=feature_names).sort_values(ascending=False)[:20]\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.barplot(x=fi.values, y=fi.index)\n",
    "    plt.title(\"Feature Importances (Decision Tree)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/feature_importances.png\")\n",
    "    plt.close()\n",
    "except Exception as e:\n",
    "    print(\"Feature importance error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22. Save trained models if you like (joblib)\n",
    "# !pip install joblib\n",
    "import joblib\n",
    "joblib.dump(lr_pipeline, \"outputs/logistic_pipeline.joblib\")\n",
    "joblib.dump(best_dt, \"outputs/decision_tree_tuned_pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. Save evaluation summary\n",
    "eval_summary = pd.DataFrame([\n",
    "    {'model':'Logistic Regression', **{k:round(v,4) for k,v in lr_metrics.items() if k in ['accuracy','precision','recall','f1']}},\n",
    "    {'model':'Decision Tree', **{k:round(v,4) for k,v in dt_metrics.items() if k in ['accuracy','precision','recall','f1']}},\n",
    "    {'model':'Decision Tree (Tuned)', **{k:round(v,4) for k,v in best_dt_metrics.items() if k in ['accuracy','precision','recall','f1']}}\n",
    "])\n",
    "eval_summary.to_csv(\"outputs/evaluation_summary.csv\", index=False)\n",
    "display(eval_summary)\n",
    "\n",
    "print(\"\\nAll outputs saved in the 'outputs/' folder. Insert the PNGs into your Word file for the report.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
